{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCKjkhPnlgJO",
        "outputId": "62e711a9-740b-4045-f21b-c48326fd8aef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Jun 22 08:10:40 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.163.01             Driver Version: 550.163.01     CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA GeForce RTX 4060 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
            "| N/A   38C    P8              1W /   80W |      12MiB /   8188MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|    0   N/A  N/A      2446      G   /usr/lib/xorg/Xorg                              4MiB |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yspJcca0mbxw",
        "outputId": "dfc4da3a-9de0-49f4-91b9-36149d3adc95"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/openai/whisper.git  -q\n",
        "# !pip install gradio -q "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "06cac6b934ce49ba9955c6bf902745eb",
            "08f494ad66f74b85ba130288f6fb3c68",
            "372978abfc1e43708308c5156aacc92e",
            "f2fd91061de3468dafbe265a84c1040f",
            "9f3d22b7753e419d8e0425e839ebf8f7",
            "45d5b2591ef2428f8f8783b49982533c",
            "b28d12da483a43e7a67770b12d4c405b",
            "ef11b62ff0fd452b8eac4297999d7681",
            "f202054127ca4ed09b57d8e16ba6aa59",
            "041935b7fef3466aa81d5372df203165",
            "00b68a49b5fd4d37b585ffa56a813b76"
          ]
        },
        "id": "cgVOk7b-XHa1",
        "outputId": "8f1b8d3a-fb9d-4e0a-87bb-3f4a8391f95c"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "from whisper.utils import WriteVTT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXWXZRFJmdbw",
        "outputId": "21938267-3927-4188-b4fa-64c1142887d4"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = whisper.load_model(\"medium\") #tiny, small, base, medium, large"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "eeIyae8wa-RO"
      },
      "outputs": [],
      "source": [
        "link = \"https://www.youtube.com/watch?v=pJ3vnUH0OkE&list=PLpdmBGJ6ELUIjFoQz22b6kfz5_k9Gv-YN&index=4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "cRCYKWpHc8Zn"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "QZWD2b3pc-Jz"
      },
      "outputs": [],
      "source": [
        "# content = requests.get(link)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "sEegd6dOkCoh"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['https://www.youtube.com/watch?v=pJ3vnUH0OkE&list=PLpdmBGJ6ELUIjFoQz22b6kfz5_k9Gv-YN&index=4', 'https://www.youtube.com/watch?v=pJ3vnUH0OkE&list=PLpdmBGJ6ELUIjFoQz22b6kfz5_k9Gv-YN&index=4']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# podcast_url = re.findall(r\"(?P<url>;https?://[^\\s]+)\", content.text)[0].split(';')[1]\n",
        "# podcast_url = re.findall(r'https?://[^\\s]+', content.text)\n",
        "\n",
        "# podcast_url = re.findall(r'https?://[^\\s\"\\'>]+\\.mp3', content.text)\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "url = link\n",
        "html = requests.get(url).text\n",
        "\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "# print(soup)\n",
        "# Find all <audio> tags or <a href=\"*.mp3\">\n",
        "podcast_url = []\n",
        "link2 = link[-20:-1]\n",
        "# links = [a['href'] for a in soup.find_all('a', href=True) if a['href'].startswith('https://') and a['href'].contains(link2)]\n",
        "# links = [a['href'] for a in soup.find_all('a', href=True) if a['href'].startswith('https://')]\n",
        "\n",
        "# links = [a['href'] for a in soup.find_all('a', href=True)]\n",
        "# from bs4 import BeautifulSoup\n",
        "# import requests\n",
        "\n",
        "# Example: load some HTML\n",
        "# html = requests.get(\"https://example.com\").text\n",
        "# soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "# Extract all href attributes from any tag\n",
        "hrefs = [tag['href'] for tag in soup.find_all(href=True)]\n",
        "for href in hrefs:\n",
        "    if (link2 in href) & (\"https://www.youtube.com\" in href):\n",
        "        podcast_url.append(href)\n",
        "\n",
        "print(podcast_url)\n",
        "\n",
        "# mp3_links = [a['href'] for a in soup.find_all('a', href=True) if a['href'].endswith(link2)]\n",
        "\n",
        "# for tag in soup.find_all('a', href=True):\n",
        "    \n",
        "#     src = tag.get('src') or tag.get('href')\n",
        "#     # src = tag.get('href')\n",
        "#     src2 = src[-10:-1]\n",
        "#     print(src)\n",
        "#     if src and (src.endswith('.mp3') | src.endswith(src2)):\n",
        "#         audio_links.append(src)\n",
        "\n",
        "# print(links)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=k6nIxWGdrS4\n",
            "[youtube] k6nIxWGdrS4: Downloading webpage\n",
            "[youtube] k6nIxWGdrS4: Downloading tv client config\n",
            "[youtube] k6nIxWGdrS4: Downloading tv player API JSON\n",
            "[youtube] k6nIxWGdrS4: Downloading ios player API JSON\n",
            "[youtube] k6nIxWGdrS4: Downloading m3u8 information\n",
            "[info] k6nIxWGdrS4: Downloading 1 format(s): 251\n",
            "[download] Destination: podcast.webm\n",
            "[download] 100% of   10.20MiB in 00:00:07 at 1.38MiB/s   \n",
            "[ExtractAudio] Destination: podcast.mp3\n",
            "Deleting original file podcast.webm (pass -k to keep)\n"
          ]
        }
      ],
      "source": [
        "# audio_links =[]\n",
        "# for audio in soup.find_all('audio'):\n",
        "#     print(audio)\n",
        "#     if audio.get('src'):\n",
        "#         audio_links.append(audio['src'])\n",
        "#         print(audio_links)\n",
        "\n",
        "import yt_dlp\n",
        "\n",
        "video_url = \"https://www.youtube.com/watch?v=k6nIxWGdrS4\"  # your video URL\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "    'outtmpl': 'podcast.%(ext)s',  # saves as podcast.mp3\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'mp3',\n",
        "        'preferredquality': '192',\n",
        "    }],\n",
        "    'quiet': False,\n",
        "}\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([video_url])\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8g0WG1ZelDC8",
        "outputId": "fb7f108a-07a4-4159-82a1-3eee9e11fcd5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/bpd/Desktop/Code/.venv/lib/python3.12/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " In today's video, I thought we can take a look at how I created this almost zero latency real-time transcription that you actually can see on the screen here. We're gonna go through some use case ideas I have for this and how you can create this too. So yeah, I think we're just gonna get started. You can also see when I stop this now, we get a log of everything we said. So yeah, perfect. Okay, so before we take a look at the code here, I want to show you one more example, just a use case I thought of. So I have this Mr. Beast YouTube video here. I'm gonna bring up the terminal. So what I'm gonna do now is I'm gonna take off my headset. I'm gonna put it around my mic here, right? Hopefully that's fine. And yeah, let's start the script and let's fire off the video. My tanks are literally about to rain missiles upon this $500,000. And any money that doesn't get destroyed, I'm giving to Blake. It's been as much money as you want trying to protect this money from all the missiles we're gonna be launching at your money. So I just build whatever I want, whatever you want. Yeah, so you can see I think that worked out pretty good. And you can see we are streaming this and we are actually real trying transcribing this. So yeah, just a cool use case. I have more planned for this. So I'm gonna do like music videos, test it out different stuff. But yeah, pretty cool, right? And you can see when I stop this now, we kind of get the log here too. So yeah, that was just basically a very simple use case. Okay, so before we move on to the next use case, let's take a look at the python code. So this is kind of built on something called fast whisperer. So this is kind of a sped up version of whisperer from OpenAI. And yeah, we are actually using our GPU here. That's why we can get such low latency. But I am running on a kind of new four series and video. So it's nothing insane, but it's working pretty good. So this is very easy to set up. I'm gonna leave a link to the git tab here. So just basically just pip install whisper and just follow the instructions here. And you can have this set up in no time. If you go back to our code, you can see we have a function that is actually recording from our microphone and creating chunks. And here we can adjust the chunk length by, yeah, we can set like one. I think that's one second. So the shorter this is the faster it streams on the in the terminal, right? And faster whisperer has of course all the models. So we can have small medium, we can have medium in English, we can have large V3. That's the best one. And we can have auto detect language. I just set mine to English for now, right? And then we come into this trulup here that is actually taking what we are recording. And it's printing it. And it's accumulating this into like a log file too that we can actually when this breaks, we can print the log here. Other than that, it's pretty simple, pretty straightforward. It's not a big script. You can see we are using CUDA course here from my GPU. And there's so few things you can adjust here to make it even quicker. But I think we're just gonna keep it as is for now. And I want to move on to kind of our next use case. Like I always, if you want to support me become a member of the channel. You can follow the link in the description below. I will put this up on our community GitHub. You will also get access to the community discord. That is if you want to support me. Other than that, just like the video, if you like this kind of content, maybe leave a comment or something. But yeah, let's move on to another use case I created for this. Okay, so the next example is gonna be a real time sentiment analysis. So you can see we have our get chat response function here that uses GPT-4. And we have such the system message to you are an expert sentiment analysis. If you scroll further down here, we have basically all the same. But here we have something that is more of a sliding window. Because we always want to keep the prompt to a set number of characters. So this is gonna be 100 characters. That means that the prompt will always be 100 characters long. And it changes over time. You will see how this works when we run it. And we create a lot of simple UI that is actually is gonna displace the sentiment. And yeah, basically all is the same. You can see we have another prompt here. So this takes the sliding window as an input. And what is the sentiment of the conversation above? So answer only with positive, neutral or negative. And yeah, kind of what this does is that it looks at what is going on in the conversation now and gives a sentiment analysis. So let's just fire up the terminal and you will see how this works in action. Okay, so when we start this now, we should get like a pop off of this UI window. So let's place it over here. And when we continue to talk now, we can see that the sentiment is changing. So let's talk about some happy stuff. So yeah, I'm very happy. I'm looking forward to my vacation. I have won a lot of money. So you can see we are changing to positive now. So if we turn this into yeah, I'm going to a funeral. I'm feeling pretty depressed. I've lost a lot of money. I'm broke. Yeah, you can see it's changing to negative. So this is basically like a real-time sentiment analysis. And if we just keep talking how you can see this is probably gonna change over time, I think we're gonna go back to neutral now. Yeah. So when we're neutral, it's just gonna keep it like this. It gets a bit messy, but I guess yeah, it works. So yeah, pretty happy with this. And it's a very simple UI. And I think it works pretty good. But yeah, nothing else to say. I think this works good. Okay, so the final example is actually gonna be a preview of Wednesday's upcoming video. So I'm not gonna spoil anything about the code or anything or actually how I'm doing this. But I'm just gonna show you how it works. Because I'm gonna work a bit more on it to the upcoming video. But this is basically up the same alley. So if we zoom in a bit here now, we fire up the terminal. So this is gonna be a bit different, but it's kind of takes off the same workflow. So let's start this now. Okay, so basically what is gonna happen here now is when I start to talk, you're gonna see images start popping up here. So let's start just talking about some red cats and maybe some white flowers. We have some green nature. We have some trees. We have some architecture. And we can actually see a blue deer running over the hill. That is gonna be very special. And some UFOs and astronauts are actually walking into the scene. The deer is fighting the astronaut. So what is gonna happen next? Well, no one knows. You can see there are some aliens coming and landing on Earth. People are scared. People are running away. And no one knows what to do. People are very scared. People are screaming. People are running. And they are very afraid. Okay, so sorry about that rant, but yeah, you can kind of see here. So what happened here is actually we are creating images from our sliding window prompt. So this goes on in pretty much real time. So the series was kind of this, right? So it's a bit strange, but I'm gonna work a bit more on it. And this is also using the faster whisperer, but we also have something else that is gonna mix into this to make this happen. I want to create some kind of UI to display the images better because this was not a good solution. But I just wanted to leave it as a preview for the upcoming video on Wednesday. Okay, so that was basically what I had for today. I hope you found it interesting. And like I said, if you want to get access to this yourself, just follow the link in the description. You can join my YouTube channel. You will get access to this private GitHub here, where I will be uploading this. Other than that, have a lot of fun with this. And I'm gonna make some improvements. Like I said, watch out for Wednesday's video. I think it's gonna be pretty cool. And yeah, have a great day and I'll see you again soon.\n"
          ]
        }
      ],
      "source": [
        "# podcast_url \n",
        "\n",
        "import whisper\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "import whisper\n",
        "model = whisper.load_model(\"base\", device=device)\n",
        "\n",
        "\n",
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"podcast.mp3\")\n",
        "\n",
        "print(result[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZy-eZFudDHu",
        "outputId": "b770af3e-f371-4a1a-b1b5-c57a909f8aec"
      },
      "outputs": [],
      "source": [
        "# !wget -O podcast.mp3 {podcast_url}\n",
        "# import requests\n",
        "\n",
        "# print(podcast_url[0])\n",
        "# url = podcast_url[0]  # assuming podcast_url is a list\n",
        "\n",
        "# response = requests.get(url, stream=True)\n",
        "# if response.status_code == 200:\n",
        "#     with open(\"podcast.mp3\", \"wb\") as f:\n",
        "#         for chunk in response.iter_content(8192):\n",
        "#             if chunk:\n",
        "#                 f.write(chunk)\n",
        "#     print(\"Download complete.\")\n",
        "# else:\n",
        "#     print(f\"Download failed with status: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIyMlkAylIoB",
        "outputId": "f707028a-5624-4c16-f1e2-e5139071f497"
      },
      "outputs": [],
      "source": [
        "# result = model.transcribe('podcast.mp3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "jzO654XjlXrG"
      },
      "outputs": [],
      "source": [
        "with open('sub.vtt', \"w\") as txt:\n",
        "  WriteVTT(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdmDqCpxVL3H",
        "outputId": "463ff9fd-1d08-47ee-b430-852ce4ecda4c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "with open('sub.vtt', \"r\") as txt:\n",
        " print('\\n'.join(txt.readlines()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 732
        },
        "id": "AWM2phq8YfzT",
        "outputId": "762dae2d-9ac5-4c9a-8b1a-781e6b87e23f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<>:12: SyntaxWarning: invalid escape sequence '\\;'\n",
            "<>:12: SyntaxWarning: invalid escape sequence '\\;'\n",
            "/tmp/ipykernel_324016/2421454190.py:12: SyntaxWarning: invalid escape sequence '\\;'\n",
            "  podcast_url = re.findall(\"(?P<url>\\;https?://[^\\s]+)\", content.text)[0].split(';')[1]\n",
            "/home/bpd/Desktop/Code/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/tmp/ipykernel_324016/2421454190.py:12: SyntaxWarning: invalid escape sequence '\\;'\n",
            "  podcast_url = re.findall(\"(?P<url>\\;https?://[^\\s]+)\", content.text)[0].split(';')[1]\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'write_vtt' from 'whisper.utils' (/home/bpd/Desktop/Code/.venv/lib/python3.12/site-packages/whisper/utils.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgradio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgr\u001b[39;00m \n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwhisper\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwhisper\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m write_vtt\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'write_vtt' from 'whisper.utils' (/home/bpd/Desktop/Code/.venv/lib/python3.12/site-packages/whisper/utils.py)"
          ]
        }
      ],
      "source": [
        "import gradio as gr \n",
        "import whisper\n",
        "from whisper.utils import WriteVTT\n",
        "import requests\n",
        "import os\n",
        "import re\n",
        "\n",
        "#model = whisper.load_model(\"medium\")\n",
        "\n",
        "def inference(link):\n",
        "  content = requests.get(link)\n",
        "  podcast_url = re.findall(\"(?P<url>\\;https?://[^\\s]+)\", content.text)[0].split(';')[1]\n",
        "  print(podcast_url)\n",
        "  \n",
        "\n",
        "  download = requests.get(podcast_url)\n",
        "\n",
        "  with open('podcast.mp3', 'wb') as f:\n",
        "    f.write(download.content)\n",
        "\n",
        "  result = model.transcribe('podcast.mp3')\n",
        "\n",
        "  with open('sub.vtt', \"w\") as txt:\n",
        "    WriteVTT(result[\"segments\"], file=txt)\n",
        "\n",
        "  return (result['text'], 'sub.vtt')\n",
        "\n",
        "  \n",
        "\n",
        "\n",
        "title=\"PodScript\"\n",
        "description=\"Get Podcast Transcript\"\n",
        "block = gr.Blocks()\n",
        "\n",
        "with block:\n",
        "    gr.HTML(\n",
        "        \"\"\"     <center> \n",
        "                <h1>PodScript</h1>\n",
        "                <img src = 'https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwww.newbreedmarketing.com%2Fhs-fs%2Fhubfs%2Fshutterstock_1125707303.jpg%3Fwidth%3D5000%26name%3Dshutterstock_1125707303.jpg&f=1&nofb=1&ipt=0ba3d9b639d63b0b737ea63cd81b241cc47f46cb519ac4ca18fd3ce6fc1376ad&ipo=images' width = '50%'></img>\n",
        "                </center>\n",
        "        \"\"\"\n",
        "    )\n",
        "    with gr.Group():\n",
        "        with gr.Box():\n",
        "          \n",
        "          link = gr.Textbox(label=\"Google Podcasts Link\")\n",
        "\n",
        "          with gr.Row().style(mobile_collapse=False, equal_height=True): \n",
        "              btn = gr.Button(\"Get PodScript ðŸª„\")\n",
        "          \n",
        "          text = gr.Textbox(\n",
        "              label=\"PodScript\", \n",
        "              placeholder=\"PodScript Output\",\n",
        "              lines=5)\n",
        "          \n",
        "          transcription = gr.File()     \n",
        "       \n",
        "          \n",
        "          btn.click(inference, inputs=[link], outputs=[text,transcription])\n",
        "\n",
        "block.launch(debug=True, enable_queue = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ8RplqOec_z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00b68a49b5fd4d37b585ffa56a813b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "041935b7fef3466aa81d5372df203165": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06cac6b934ce49ba9955c6bf902745eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08f494ad66f74b85ba130288f6fb3c68",
              "IPY_MODEL_372978abfc1e43708308c5156aacc92e",
              "IPY_MODEL_f2fd91061de3468dafbe265a84c1040f"
            ],
            "layout": "IPY_MODEL_9f3d22b7753e419d8e0425e839ebf8f7"
          }
        },
        "08f494ad66f74b85ba130288f6fb3c68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45d5b2591ef2428f8f8783b49982533c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_b28d12da483a43e7a67770b12d4c405b",
            "value": ""
          }
        },
        "372978abfc1e43708308c5156aacc92e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef11b62ff0fd452b8eac4297999d7681",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f202054127ca4ed09b57d8e16ba6aa59",
            "value": 0
          }
        },
        "45d5b2591ef2428f8f8783b49982533c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3d22b7753e419d8e0425e839ebf8f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b28d12da483a43e7a67770b12d4c405b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ef11b62ff0fd452b8eac4297999d7681": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f202054127ca4ed09b57d8e16ba6aa59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f2fd91061de3468dafbe265a84c1040f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_041935b7fef3466aa81d5372df203165",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_00b68a49b5fd4d37b585ffa56a813b76",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
